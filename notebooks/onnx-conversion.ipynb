{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "429f6242-c892-40fc-86e5-1f076d516baf",
   "metadata": {},
   "source": [
    "This notebook shows how to optimize the ResNetV2101 model we saw in `resnet-export.ipynb` notebook. We will use [ONNX](https://onnx.ai/) for this purpose. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea7396f-a09d-4d30-9511-9ef46d3fe07f",
   "metadata": {},
   "source": [
    "## Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "956baad6-4796-4b46-8184-258fda5f488c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tfx-bsl 1.9.0 requires google-api-python-client<2,>=1.7.11, but you have google-api-python-client 2.52.0 which is incompatible.\n",
      "tfx-bsl 1.9.0 requires pyarrow<6,>=1, but you have pyarrow 8.0.0 which is incompatible.\n",
      "tensorflow-transform 1.9.0 requires pyarrow<6,>=1, but you have pyarrow 8.0.0 which is incompatible.\n",
      "apache-beam 2.40.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.4 which is incompatible.\n",
      "apache-beam 2.40.0 requires pyarrow<8.0.0,>=0.15.1, but you have pyarrow 8.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install onnxruntime==1.11.0 numpy==1.21.0 tf2onnx -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5231a95e-ccae-4201-bae7-d637f7328da9",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09d48ba2-5166-41c1-954f-4e7acaddd8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import onnx\n",
    "import timeit\n",
    "import tf2onnx\n",
    "import numpy as np\n",
    "import onnxruntime as ort"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b1a2af-d469-483b-9cd4-b07f646d9d81",
   "metadata": {},
   "source": [
    "## Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d6898e7-e4fe-491e-b33c-64f479518b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a159a8e6-751c-4bea-ac22-40e173ee02e2",
   "metadata": {},
   "source": [
    "## Load the ResNetV2101 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f0a91ad-0467-4d38-aec4-0d9e9c9b515d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfhub_model = tf.keras.Sequential(\n",
    "    [hub.KerasLayer(\"https://tfhub.dev/google/imagenet/resnet_v2_101/classification/5\")]\n",
    ")\n",
    "\n",
    "tfhub_model.build([None, IMG_SIZE, IMG_SIZE, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf4dc8d-9854-405a-b355-851a1279ab0d",
   "metadata": {},
   "source": [
    "## Convert to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62f47a15-9c6f-4402-8fb4-b0dc10e2b3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tf2onnx/tf_loader.py:711: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tf2onnx/tf_loader.py:711: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n"
     ]
    }
   ],
   "source": [
    "input_signature = [\n",
    "    tf.TensorSpec([None, IMG_SIZE, IMG_SIZE, 3], tf.float32)\n",
    "]\n",
    "onnx_model, _ = tf2onnx.convert.from_keras(tfhub_model, input_signature, opset=15)\n",
    "onnx_model_path = \"resnetv2101.onnx\"\n",
    "onnx.save(onnx_model, onnx_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b884e864-e6bf-41b6-8c35-50757a0157cd",
   "metadata": {},
   "source": [
    "## Ensure the ONNX and TF Hub model outputs match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4279be1b-a3aa-4da7-8f07-fd0d809270cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_inputs = tf.random.normal((1, IMG_SIZE, IMG_SIZE, 3))\n",
    "dummy_inputs_numpy = dummy_inputs.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a4ea34f-9eae-4cd7-8946-1af0a7d44a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_outputs = tfhub_model(dummy_inputs, training=False)\n",
    "\n",
    "sess = ort.InferenceSession(onnx_model_path)\n",
    "ort_outputs = sess.run(None, {\"args_0\": dummy_inputs_numpy})\n",
    "\n",
    "np.allclose(tf_outputs.numpy(), ort_outputs, rtol=1e-5, atol=1e-05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8bc1e4-6ac1-4b0c-b514-21415f8c9ab6",
   "metadata": {},
   "source": [
    "## Benchmark latency of both the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a647a421-cf8f-49a8-854c-32e764c46868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking TF model...\n",
      "Average latency (seconds): 0.206272908560004.\n"
     ]
    }
   ],
   "source": [
    "print(\"Benchmarking TF model...\")\n",
    "for _ in range(2):\n",
    "    _ = tfhub_model(dummy_inputs, training=False)\n",
    "\n",
    "# Timing\n",
    "tf_runtimes = timeit.repeat(\n",
    "    lambda: tfhub_model(dummy_inputs, training=False), number=1, repeat=25\n",
    ")\n",
    "print(f\"Average latency (seconds): {np.mean(tf_runtimes)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cf7abe3-3c35-48d3-b8ed-7d840e085702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking ONNX model...\n",
      "Average latency (seconds): 0.06843939660000614.\n"
     ]
    }
   ],
   "source": [
    "print(\"Benchmarking ONNX model...\")\n",
    "for _ in range(2):\n",
    "    _ = sess.run(None, {\"args_0\": dummy_inputs_numpy})\n",
    "\n",
    "# Timing\n",
    "onnx_runtimes = timeit.repeat(\n",
    "    lambda: sess.run(None, {\"args_0\": dummy_inputs_numpy}), number=1, repeat=25\n",
    ")\n",
    "print(f\"Average latency (seconds): {np.mean(onnx_runtimes)}.\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-9.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-9:m94"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
